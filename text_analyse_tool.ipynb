{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlF4agpKQIp1Km8pFceA68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricLe1404/text_analyse_tool/blob/main/text_analyse_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Display welcome message to the user\n",
        "Prompt user to:\n",
        "    - Type or paste text\n",
        "    - OR upload a text/document file\n",
        "    - (Optional) Provide second text for comparison\n",
        "\n",
        "If user uploads a file:\n",
        "    - Extract text from file (.txt, .pdf, .docx, .csv)\n",
        "\n",
        "If user enters URL:\n",
        "    - Scrape text content from webpage\n",
        "\n",
        "Store text(s) for analysis\n",
        "\n",
        "Ask user to enable/disable optional features:\n",
        "    - Spelling check\n",
        "    - Auto-correction\n",
        "    - Formality detection\n",
        "    - Sentiment analysis\n",
        "    - Word cloud and charts\n",
        "    - Summary dashboard\n",
        "    - Comparison mode\n",
        "\n",
        "Clean the input text(s):\n",
        "    - Lowercase\n",
        "    - Remove punctuation\n",
        "    - Tokenize text\n",
        "    - Remove stopwords\n",
        "\n",
        "If spelling check is enabled:\n",
        "    - Highlight misspelled words\n",
        "    - Apply auto-correction (if selected)\n",
        "\n",
        "For each input text:\n",
        "    - Count total words\n",
        "    - Count unique words\n",
        "    - Count sentences\n",
        "    - Calculate average word length\n",
        "    - Identify most frequent words\n",
        "\n",
        "Detect language using langdetect\n",
        "Detect formality based on informal words, contractions, and emojis\n",
        "Perform sentiment analysis (TextBlob or VADER)\n",
        "    - Return polarity score and emoji\n",
        "\n",
        "\n",
        "If visualizations enabled:\n",
        "    - Generate word cloud\n",
        "    - Generate bar chart of word frequency\n",
        "    - (Optional) Generate pie chart of sentiment\n",
        "\n",
        "Compile results into a summary:\n",
        "    - Key statistics\n",
        "    - Tone and formality feedback\n",
        "    - Detected language\n",
        "    - Most frequent words\n",
        "    - Suggestions for improvement\n",
        "\n",
        "Display option to:\n",
        "    - Copy to clipboard\n",
        "    - Download PDF\n",
        "    - Save to history\n",
        "\n",
        "Offer options:\n",
        "    - Analyze another text\n",
        "    - Compare with a second text\n",
        "    - Exit program\n"
      ],
      "metadata": {
        "id": "nja4DjrQ4gGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "text = \"I love this! It's absolutely fantastic ðŸ˜Š\"\n",
        "\n",
        "scores = analyzer.polarity_scores(text)\n",
        "print(scores)\n",
        "compound = scores['compound']\n",
        "\n",
        "if compound >= 0.05:\n",
        "    print(\"Sentiment: Positive ðŸ˜Š\")\n",
        "elif compound <= -0.05:\n",
        "    print(\"Sentiment: Negative ðŸ˜ž\")\n",
        "else:\n",
        "    print(\"Sentiment: Neutral ðŸ˜\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paWKCPV4Y64a",
        "outputId": "64a77441-f5c7-4e60-e0cb-fcaad921f988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.264, 'pos': 0.736, 'compound': 0.855}\n",
            "Sentiment: Positive ðŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XsODohLUY3ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO6aXMgEYTPu",
        "outputId": "e10ca60e-e389-49fb-d9f6-d1b650c88982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WfU267lMY3Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import streamlit\n",
        "    print(\"streamlit is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"streamlit is not installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG_UUxHTAw1m",
        "outputId": "35f6725b-413d-4dc6-df45-db9dcbaa1715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "streamlit is not installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import matplotlib\n",
        "    print(\"matplotlib is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"matplotlib is not installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlfsevW-AXvH",
        "outputId": "9f5fd032-6105-49ce-b310-e826092bc5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib is already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import re\n",
        "    print(\"re is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"re is not installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-UDDmzzAKSx",
        "outputId": "424e880a-fde3-481b-9d63-7d4f589552ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "re is already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Eft0GgoAEcn",
        "outputId": "5fe3b2be-154e-47a3-fcab-9abf6505d2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txWlI2H3cy5d",
        "outputId": "a4363b2c-d578-46ab-b915-d7f2f93abd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "textblob is already installed.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import textblob\n",
        "    print(\"textblob is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"textblob is not installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_8_kNcE_3Fn",
        "outputId": "3bb4525a-80de-46d8-e41a-efd7123fc5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import nltk\n",
        "    print(\"nltk is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"nltk is not installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA6F3xkD-MAf",
        "outputId": "d0093093-c96b-4c47-be59-f111284e13d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nltk is already installed.\n"
          ]
        }
      ]
    }
  ]
}